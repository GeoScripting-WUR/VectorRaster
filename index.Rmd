---
title: "Raster Vector integration in R"
author: "Loïc Dutrieux"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 4
---

# Today (12/01/2015)

- Morning: Self-study from home or PC38 - Go through the following tutorial
- 1330-1430: Questions and clarifications with Loïc
- Rest of the afternoon: Do/finalise the exercise.

# Today's learning objectives
At the end of the lecture, you should be able to


* Have an overview of what can be achived when combining raster and vector data in R
* Be able to extract raster data using vector data


# Introduction

In the previous lectures we saw how to deal with [raster](http://geoscripting-wur.github.io/IntroToRaster/) data using R, as well as how to deal with [vector](http://geoscripting-wur.github.io/IntroToVector/) data and the multiple classes of the sp package. In the current lesson, we'll see what can be done when the two worlds of vector data and raster data intersect.

# Conversions

You will find some utilities in R to convert data from raster to vector format and vice-versa. However, whenever you start converting objects, you should wonder whether you are taking the right approach to solve your problem. An approach that does not involve converting your data from vector to raster or the opposite should almost always be preferred.

As a result, because these functions are only useful for some very particular situations, I only give below a brief description of them.

## Vector to raster

There is one function that allows to convert a object in vector for to a raster object. It is the `rasterize()` function.

## Raster to vector

Two functions allow to convert raster data to vector; the `rasterToPoints()` and `rasterToPolygons()` functions. The latter can be useful to convert the result of a classification. In that case, set `dissolve =` to `TRUE`.

# Geometric operations

Raw raster data do not usually conform to any notion of administrative or geographical boundaries. Vector data (and extents) can be used to mask or crop data to a desired region of interest.

## `crop`

Cropping consists in reducing the extent of a spatial object to a smaller extent. As a result, the output of `crop()` will automatically be rectangular and will not consider any features such as polygons to perform the subsetting. It is often useful to crop data as tightly as possible to the area under investigation to reduce the amount of data and have a more focused view when visualizing the data.
Crop uses objects of class `extent` to define the new extent, or ''any object that can be coerced to an extent''. This means that practically all spatial objects (raster or vector) can be used directly in crop. Considering two raster objects `r1` and `r2` with `r2` smaller than `r1`, you can simply use `crop(r1, r2)` in order to crop `r1` to the extent of `r2`.
If you want to 'cut' your raster data following the contours of a polygon, then you need to use the `mask()` function.

You can easily define an extent interactively (by clicking) thanks to the `drawExtent()` function.

## Mask

Mask can be used with almost all spatial objects to mask (set to NA), values of a raster* object. When used with a SpatialPolygon* object, mask will keep values of the raster overlayed by polygons and mask the values outside of polygons.

Note the very useful `inverse=` argument of `mask()`, which allows to mask the inverse of the area covered by the features. We will use this feature of mask later in the tutorial to exclude water areas of a raster, defined in an independent SpatialPolygons* object.
 
# Extract

The most common operation when combining vector and raster data is the extraction. It simply consists in extracting the values of a raster object for locations specified by a vector object. The object can be one of the class of the sp package, or an extent object.

When using `extract()` with SpatialPolygons* or SpatialLines* and feature are overlaying or intersecting several features, a function (`fun =`) can also be used to summarize the values. Note that although most often the function `min`, `max`, `mean` and `median` functions are used for the spatial aggregation, any custom made function can be used.

# Example - *A simple land cover classification of Wageningen from Landsat 8 data*

In the example below we will do a simple supervised land cover classification of Wageningen. The example uses the same data as you used in the [exercise](http://geoscripting-wur.github.io/IntroToRaster/#exercise-design-a-pre-processing-chain-to-assess-change-in-ndvi-over-time) of the raster lesson.

Step by step we will:

- Download the Landsat 8 data of Wageningen
- Download and prepare administrative boundary data of the Netherlands
- Download Water area data of Wageningen
- Mask the data to match the boundaries of the city
- 


```{r, eval=FALSE}
library(raster)
# Download, unzip and load the data
download.file(url = 'https://github.com/GeoScripting-WUR/VectorRaster/raw/gh-pages/data/landsat8.zip', destfile = 'landsat8.zip', method = 'auto')

unzip('landsat8.zip')
# Identify the right file
landsatPath <- list.files(pattern = glob2rx('LC8*.grd'), full.names = TRUE)

wagLandsat <- brick(landsatPath)
```

```{r, echo=FALSE}
library(raster)
wagLandsat <- brick('data/LC81970242014109LGN00.grd')
```

We can start by visualizing the data, since it is a multispectral image, we can use `plotRGB()` to do so.


```{r, fig.align='center'}
# plotRGB does not support negative values, so that they need to be removed
wagLandsat[wagLandsat < 0] <- NA
plotRGB(wagLandsat, 5, 4, 3)
```

```{r}
# Download municipality boundaries
nlCity <- getData('GADM',country='NLD', level=3)
class(nlCity)
head(nlCity@data)
```

It seems that the municipality names are in the `NAME_2` column. So that we can subset the SpatialPolygonsDataFrame to the city of Wageningen alone.


```{r}
wagContour <- nlCity[nlCity$NAME_2 == 'Wageningen',]
```

We can use the resulting `wagContour` object, to mask the values out of Wageningen, but first, since the two objects are in different coordinate systems, we need to reproject one to the projection of the other.

> **Question:** Would you rather reproject a raster or a vector layer? Give two reasons.

```{r}
# Load rgdal library (needed to reproject data)
library(rgdal)
wagContourUTM <- spTransform(wagContour, CRS(proj4string(wagLandsat)))
```

Now that the two objects are in the same CRS, we can do the masking and visualize the result. Let's first crop and then mask, to see the difference.

```{r, fig.align='center', fig.show='hold', fig.cap='Example of crop and mask'}
wagLandsatCrop <- crop(wagLandsat, wagContourUTM)
wagLandsatSub <- mask(wagLandsat, wagContourUTM)

# Set graphical parameters (one row and two columns)
opar <- par(mfrow=c(1,2))
plotRGB(wagLandsatCrop, 5, 4, 3, main = 'Crop()')
plotRGB(wagLandsatSub, 5, 4, 3, main = 'Mask()')
plot(wagContourUTM, add = TRUE)
# Reset graphical parameters
par(opar)
```

We also have a water mask of Wageningen in vector format. Let's download it and also reproject it to the CRS of the Landsat data.

```{r, eval=FALSE}
download.file(url = 'https://github.com/GeoScripting-WUR/VectorRaster/raw/gh-pages/data/wageningenWater.zip', destfile = 'wageningenWater.zip', method = 'auto')
unzip('wageningenWater.zip')
# The 
ogrListLayers('waterWageningen.sqlite')
water <- readOGR('', layer = 'waterwageningen')
waterUTM <- spTransform(water, CRS(proj4string(wagLandsat)))
```

```{r, echo=FALSE}
water <- readOGR('data/Water.shp', layer = 'Water')
waterUTM <- spTransform(water, CRS(proj4string(wagLandsat)))
```

```{r, fig.align='center'}
wagLandsatSubW <- mask(wagLandsatSub, mask = waterUTM, inverse = TRUE)
plotRGB(wagLandsatSubW, 5, 4, 3)
plot(waterUTM, col = 'blue', add = TRUE)
```

For the rest of the example, we'll use the `wagLandsatCrop` object, for I have a few doubts about the spatial accuracy of the two vector layers we used in the masking steps.

## Build a calibration dataset in Google Earth

Open Google Earth, in places, right click on ''Temporary Places'' and select ''Add - Folder''; name it appropriately. Add new placemaks to that folder, and put the interpreted land cover in the description field. Keep it to a few classes, such as agric, forest, water, urban. I also added flood, to categorize the flood plain nearby the river. When you are done, save the file.

Load the newly created kml file using the `readOGR()` function. The object should be a SpatialPointsDataFrame and the information created is stored in the description column of the data frame.

```{r, eval=FALSE}
# Change to the correct file path and layer name
samples <- readOGR('sampleLongLat.kml', layer = 'sampleLongLat')
```

```{r, echo = FALSE}
samples <- readOGR('data/sampleLongLat2.kml', layer = 'sampleLongLat')
```

```{r}
samplesUTM <- spTransform(samples, CRS(proj4string(wagLandsatCrop)))
samplesUTM@coords <- coordinates(samplesUTM)[,-3]
calib <- extract(wagLandsatCrop, samplesUTM, df=TRUE)
calib2 <- cbind(samplesUTM$description, calib)
colnames(calib2)[1] <- 'lc'
str(calib2)
```

Don't focus too much on the algorithm used, the import part for this tutorial is the data extraction and the following data frame manipulation.


```{r}
library(randomForest)
model <- randomForest(lc ~ band1 + band2 + band3 + band4 + band5 + band6 + band7, data = calib2)
lcMap <- predict(wagLandsatCrop, model = model)
```

Let's visualize the output. The function `levelplot()` from the rasterVis package is a convenient function to plot categorical raster data.

```{r, fig.align='center'}
library(rasterVis)
levelplot(lcMap, col.regions = c('green', 'brown', 'darkgreen', 'lightgreen', 'grey', 'blue'))
```

OK, we've seen better land cover maps of Wageningen, but given the amount of training data we used, it is not too bad. A larger calibration dataset would certainly result in a better accuracy.

## Extract raster values along a transect

Another use of the `extract()` function can be to visualize or analyse data along transects.
In the following example, we will run a transect across Belgium and visualize the change in elevation.

Let's first download the elevation data of Belgium, using the `getData()` function of the raster package.

```{r}
bel <- getData('alt', country='BEL', mask=TRUE) ## SRTM 90m height data
# Display metadata
bel
```

`bel` is a RasterLayer

We can start by visualizing the data.

```{r, fig.align='center'}
plot(bel)
```

Everything seems correct.

We want to look at a transect, which we can draw by hand by selecting two points by clicking. The `drawLine()` function will help us do that.


```{r, eval=FALSE}
line <- drawLine()
```

```{r, echo=FALSE, fig.align='center'}
line <- readRDS('data/line.rds')
plot(bel)
plot(line, col = 'red', add = TRUE)
```

Then the elevation values can simply be extracted using `extract()`. Note the use of the `along.with=` argument which ensures that the samples remain in order along the segment. 

```{r}
alt <- extract(bel, line, along = TRUE)
```

We can already plot the result as follows, but the x axis does not really provide any indication of distance.

```{r, fig.align='center'}
plot(alt[[1]])
```

In order to make an index for the x axis, we can calculate the distance between the two extremities of the transect, using `distHaversine()` from the geosphere package.

```{r}
library(geosphere)
# Calculate great circle distance between the two ends of the line
dist <- distHaversine(coordinates(line)[[1]][[1]][1,], coordinates(line)[[1]][[1]][2,])
# Format a vector for use as x axis index
distanceVector <- seq(0, dist, along.with = alt[[1]])
```

> **Question**: Why can't we simply use the `LineLength()` function from the sp package?

> Hint, look at the CRS in which we are working, and at the help page of the `distHaversine()` function

Note that there is a small approximation on the position of the line and the distances between the samples as the real shortest path between two points is not a straight line in lat-long.
We could also have:

- Projected the raster and the line to a projected coordinate system, or
- Made a true greatCircle line using `greatCircle()` from the sp package and extracted the elevation values from it.

Let's now visualize the final output.

```{r, fig.align='center', fig.show='hold'}
# Visualize the output
# Set graphical parameters (grid with 2 rows and 1 column)
opar <- par(mfrow = c(2,1))
plot(bel, main = 'Altitude (m)')
plot(line, add = TRUE)
plot(distanceVector/1000, alt[[1]], type = 'l',
     main = 'Altitude transect Belgium',
     xlab = 'Distance (Km)',
     ylab = 'Altitude (m)',
     las = 1)
# Reset graphical parameters to default
par(opar)
```


# Exercise

[product details](https://lpdaac.usgs.gov/products/modis_products_table/mod13a3)

What about provinces (see `?aggregate()`)